{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tushare as ts\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "column_names = ['Date','Open','High','Low','Close','Volumn','Value','Rate','Mark']\n",
    "file_name = \"Desktop/sh600108_D_ExDiv.csv\"\n",
    "\n",
    "# get data\n",
    "\n",
    "# preprocess\n",
    "def transform_calendar_csv():\n",
    "    df = pd.read_csv(\"/Volumes/Expansion Drive/calendar/dates_master.csv\", header=None, index_col=0) \n",
    "    return df\n",
    "\n",
    "def transform_single_csv(df_calendar, file_name):\n",
    "    df = pd.read_csv(file_name, header=None, index_col=0)\n",
    "    df = pd.concat([df, df_calendar], axis=1, join='inner')\n",
    "    df = df.reset_index(drop=False)\n",
    "    df.columns = column_names\n",
    "    return df\n",
    "\n",
    "def calculate_moving_average(df, periods, price_choice=\"Close\"):\n",
    "    first_values = np.array([])\n",
    "    second_values = np.array([])\n",
    "    for i in range(periods+1, len(df)):\n",
    "        first_value = 0\n",
    "        second_value = 0\n",
    "        for j in range(0, periods):\n",
    "            first_rate = df[\"Rate\"][i-j-2]/df[\"Rate\"][i-1]\n",
    "            second_rate = df[\"Rate\"][i-j-1]/df[\"Rate\"][i-1]\n",
    "            first_value += df[price_choice][i-j-2] * first_rate\n",
    "            second_value += df[price_choice][i-j-1] * second_rate\n",
    "        first_value = first_value/periods\n",
    "        second_value = second_value/periods\n",
    "        first_values = np.append(first_values, np.array([first_value]))\n",
    "        second_values = np.append(second_values, np.array([second_value]))\n",
    "    df = df[periods+1:]\n",
    "    first_column = \"first_{}_averages\".format(periods)\n",
    "    second_column = \"second_{}_averages\".format(periods)   \n",
    "    df[first_column] = first_values\n",
    "    df[second_column] = second_values\n",
    "    return df\n",
    "\n",
    "def combine_moving_averages(df, short_periods, long_periods, price_choice=\"Close\"):\n",
    "    short_df = calculate_moving_average(df, short_periods, price_choice)\n",
    "    long_df = calculate_moving_average(df, long_periods, price_choice)   \n",
    "    short_df = short_df[long_periods-short_periods:]\n",
    "    long_first_column = \"first_{}_averages\".format(long_periods)\n",
    "    long_second_column = \"second_{}_averages\".format(long_periods)\n",
    "    short_df[long_first_column] = long_df[long_first_column]\n",
    "    short_df[long_second_column] = long_df[long_second_column]  \n",
    "    return short_df \n",
    "\n",
    "def find_average_matches(df, short_periods, long_periods):\n",
    "    match_points = np.array([])\n",
    "    first_value_differences = np.array([])\n",
    "    second_value_differences = np.array([])  \n",
    "    short_first_column = \"first_{}_averages\".format(short_periods)\n",
    "    short_second_column = \"second_{}_averages\".format(short_periods)\n",
    "    long_first_column = \"first_{}_averages\".format(long_periods)\n",
    "    long_second_column = \"second_{}_averages\".format(long_periods)\n",
    "    for i in range(len(df)):\n",
    "        real_index = i+long_periods+1\n",
    "        first_value_difference = df[short_first_column][real_index] - df[long_first_column][real_index]\n",
    "        second_value_difference = df[short_second_column][real_index] - df[long_second_column][real_index]\n",
    "        first_value_differences = np.append(first_value_differences, np.array([first_value_difference]))\n",
    "        second_value_differences = np.append(second_value_differences, np.array([second_value_difference]))    \n",
    "        if (second_value_differences[-1]>=0 and first_value_differences[-1]<0):\n",
    "            match_points = np.append(match_points, np.array([1]))\n",
    "        elif (second_value_differences[-1]<=0 and first_value_differences[-1]>0):\n",
    "            match_points = np.append(match_points, np.array([-1]))     \n",
    "        else:\n",
    "            match_points = np.append(match_points, np.array([0]))        \n",
    "    df[\"match_points\"] = match_points\n",
    "    return df\n",
    "\n",
    "def calculate_daily_earnings(df, long_periods, buy_column=\"Open\", sell_column=\"Open\"):\n",
    "    buy_in = False\n",
    "    daily_earning_rates = np.array([])\n",
    "    for i in range(len(df)):\n",
    "        real_index = i+long_periods+1\n",
    "        match_point = df[\"match_points\"][real_index]      \n",
    "        if (match_point == 1 and not buy_in):\n",
    "            daily_earning_rate = (df[\"Close\"][real_index] - df[buy_column][real_index])/df[buy_column][real_index]\n",
    "            daily_earning_rates = np.append(daily_earning_rates, np.array([daily_earning_rate]))\n",
    "            buy_in = True\n",
    "        elif (match_point == -1 and buy_in):\n",
    "            last_rate = df[\"Rate\"][real_index-1]/df[\"Rate\"][real_index]\n",
    "            adjust_last_close = df[\"Close\"][real_index-1] * last_rate\n",
    "            daily_earning_rate = (df[sell_column][real_index]-adjust_last_close)/adjust_last_close\n",
    "            daily_earning_rates = np.append(daily_earning_rates, np.array([daily_earning_rate]))\n",
    "            buy_in = False\n",
    "        elif (match_point == 0 and buy_in):   \n",
    "            last_rate = df[\"Rate\"][real_index-1]/df[\"Rate\"][real_index]\n",
    "            adjust_last_close = df[\"Close\"][real_index-1] * last_rate\n",
    "            daily_earning_rate = (df[\"Close\"][real_index]-adjust_last_close)/adjust_last_close\n",
    "            daily_earning_rates = np.append(daily_earning_rates, np.array([daily_earning_rate]))\n",
    "        else:\n",
    "            daily_earning_rates = np.append(daily_earning_rates, np.array([0]))\n",
    "    df[\"daily_earning_rates\"] = daily_earning_rates    \n",
    "    return df \n",
    "\n",
    "def combine_daily_earnings_to_calendar(df, df_calendar):\n",
    "    df = df.set_index('Date')\n",
    "    df = pd.concat([df, df_calendar], axis=1, join='outer')\n",
    "    df = df.reset_index(drop=False)\n",
    "    df['daily_earning_rates']=df['daily_earning_rates'].fillna(0)\n",
    "    return df\n",
    "\n",
    "def calculate_cumulate_earnings(df):\n",
    "    cumulate_earning_rates = np.array([])\n",
    "    for i in range(len(df)):\n",
    "        daily_earning_rate = df[\"daily_earning_rates\"][i]\n",
    "        if(len(cumulate_earning_rates)==0):\n",
    "            cumulate_earning_rate = daily_earning_rate\n",
    "        else:\n",
    "            cumulate_earning_rate = daily_earning_rate + cumulate_earning_rates[-1]\n",
    "        cumulate_earning_rates = np.append(cumulate_earning_rates, np.array([cumulate_earning_rate]))\n",
    "    df[\"cumulate_earning_rates\"] = cumulate_earning_rates\n",
    "    return df\n",
    "\n",
    "def combine_multiple_cumulate_earnings():\n",
    "    files_address = \"/Volumes/Expansion Drive/tkline\"\n",
    "    #test_address = \"Desktop/test case\"\n",
    "    #file_names = np.array(os.listdir(test_address))\n",
    "    file_names = np.array(os.listdir(files_address))\n",
    "    df_combine = pd.read_csv(\"/Volumes/Expansion Drive/calendar/dates_master.csv\", header=None)\n",
    "    for file_name in file_names:\n",
    "        df_calendar= transform_calendar_csv()\n",
    "        #df = transform_single_csv(df_calendar, test_address+\"/\"+file_name)\n",
    "        df = transform_single_csv(df_calendar, files_address+\"/\"+file_name)\n",
    "        df2 = combine_moving_averages(df, 5, 20, price_choice=\"Close\")\n",
    "        df3 = find_average_matches(df2, 5, 20)\n",
    "        df4 = calculate_daily_earnings(df3, 20, buy_column=\"Open\", sell_column=\"Open\")\n",
    "        df5 = combine_daily_earnings_to_calendar(df4, df_calendar)\n",
    "        df6 = calculate_cumulate_earnings(df5)\n",
    "        df_combine[file_name] = df6[\"cumulate_earning_rates\"]\n",
    "    return df_combine\n",
    "\n",
    "def mean_multiple_earnings(df_combine):\n",
    "    mean_earning_rates = np.array([])\n",
    "    files_address = \"/Volumes/Expansion Drive/tkline\"\n",
    "    test_address = \"Desktop/test case\"\n",
    "    #file_names = np.array(os.listdir(test_address))\n",
    "    file_names = np.array(os.listdir(files_address))\n",
    "    counts = df_combine.shape[1]-2\n",
    "    for i in range(len(df_combine)):\n",
    "        sums=0\n",
    "        for j in file_names :\n",
    "            sums+=df_combine[j][i]\n",
    "        mean_earning_rates = np.append(mean_earning_rates, np.array([sums/counts]))\n",
    "    df_combine[\"mean\"] = mean_earning_rates\n",
    "    return df_combine\n",
    "\n",
    "# main\n",
    "if __name__ == \"__main__\":\n",
    "    df_combine = combine_multiple_cumulate_earnings()\n",
    "    df_mean = mean_multiple_earnings(df_combine)\n",
    "    #print(df_mean[\"mean\"][-5:])\n",
    "    df_mean[\"mean\"].plot()\n",
    "    #df_combine[\"sh600000_D_ExDiv.csv\"].plot()\n",
    "    #df_combine[\"sh600108_D_ExDiv.csv\"].plot()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    df_calendar= transform_calendar_csv()\n",
    "    df = transform_single_csv(df_calendar)\n",
    "    df2 = combine_moving_averages(df, 5, 20, price_choice=\"Close\")\n",
    "    df3 = find_average_matches(df2, 5, 20)\n",
    "    df4 = calculate_earnings(df3, 20, buy_column=\"Open\", sell_column=\"Open\")\n",
    "    df5 = combine_daily_earnings_to_calendar(df4, df_calendar)\n",
    "    df6 = calculate_cumulate_earnings(df5)\n",
    "    \n",
    "    print(df6[\"cumulate_earning_rates\"][170:300])\n",
    "    \n",
    "    df6[\"cumulate_earning_rates\"].plot()\n",
    "    df6[\"Close\"].plot()\n",
    "    plt.show()\n",
    "    '''\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# SH600108 Moving Average Earning\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tushare as ts\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "column_names = ['Date','Open','High','Low','Close','Volumn','Value','Rate']\n",
    "file_name = \"Desktop/sh600108_D_ExDiv.csv\"\n",
    "\n",
    "def transform_single_csv():\n",
    "    df = pd.read_csv(file_name, header=None)\n",
    "    df.columns = column_names\n",
    "    return df\n",
    "\n",
    "def calculate_moving_average(df, periods, price_choice=\"Close\"):\n",
    "    first_values = np.array([])\n",
    "    second_values = np.array([])  \n",
    "    for i in range(periods+1, len(df)):\n",
    "        first_value = 0\n",
    "        second_value = 0\n",
    "        for j in range(0, periods):\n",
    "            first_rate = df[\"Rate\"][i-j-2]/df[\"Rate\"][i-1]\n",
    "            second_rate = df[\"Rate\"][i-j-1]/df[\"Rate\"][i-1]\n",
    "            first_value += df[price_choice][i-j-2] * first_rate\n",
    "            second_value += df[price_choice][i-j-1] * second_rate\n",
    "        first_value = first_value/periods\n",
    "        second_value = second_value/periods\n",
    "        first_values = np.append(first_values, np.array([first_value]))\n",
    "        second_values = np.append(second_values, np.array([second_value]))\n",
    "    df = df[periods+1:]\n",
    "    first_column = \"first_{}_averages\".format(periods)\n",
    "    second_column = \"second_{}_averages\".format(periods)    \n",
    "    df[first_column] = first_values\n",
    "    df[second_column] = second_values\n",
    "    return df\n",
    "\n",
    "def combine_moving_averages(df, short_periods, long_periods, price_choice=\"Close\"):\n",
    "    short_df = calculate_moving_average(df, short_periods, price_choice)\n",
    "    long_df = calculate_moving_average(df, long_periods, price_choice)  \n",
    "    short_df = short_df[long_periods-short_periods:]\n",
    "    long_first_column = \"first_{}_averages\".format(long_periods)\n",
    "    long_second_column = \"second_{}_averages\".format(long_periods)\n",
    "    short_df[long_first_column] = long_df[long_first_column]\n",
    "    short_df[long_second_column] = long_df[long_second_column]\n",
    "    return short_df \n",
    "\n",
    "def find_average_matches(df, short_periods, long_periods):\n",
    "    match_points = np.array([])  \n",
    "    first_value_differences = np.array([])\n",
    "    second_value_differences = np.array([])\n",
    "    short_first_column = \"first_{}_averages\".format(short_periods)\n",
    "    short_second_column = \"second_{}_averages\".format(short_periods)\n",
    "    long_first_column = \"first_{}_averages\".format(long_periods)\n",
    "    long_second_column = \"second_{}_averages\".format(long_periods)\n",
    "    for i in range(len(df)):\n",
    "        real_index = i+long_periods+1\n",
    "        first_value_difference = df[short_first_column][real_index] - df[long_first_column][real_index]\n",
    "        second_value_difference = df[short_second_column][real_index] - df[long_second_column][real_index]\n",
    "        first_value_differences = np.append(first_value_differences, np.array([first_value_difference]))\n",
    "        second_value_differences = np.append(second_value_differences, np.array([second_value_difference]))    \n",
    "        if (second_value_differences[-1]>=0 and first_value_differences[-1]<0):\n",
    "            match_points = np.append(match_points, np.array([1]))\n",
    "        elif (second_value_differences[-1]<=0 and first_value_differences[-1]>0):\n",
    "            match_points = np.append(match_points, np.array([-1]))     \n",
    "        else:\n",
    "            match_points = np.append(match_points, np.array([0]))\n",
    "    df[\"match_points\"] = match_points\n",
    "    return df\n",
    "\n",
    "def calculate_earnings(df, long_periods, buy_column=\"Open\", sell_column=\"Open\"):\n",
    "    buy_in = False \n",
    "    daily_earning_rates = np.array([])\n",
    "    cumulate_earning_rates = np.array([])\n",
    "    for i in range(len(df)):\n",
    "        real_index = i+long_periods+1\n",
    "        match_point = df[\"match_points\"][real_index]\n",
    "        if (match_point == 1 and not buy_in):\n",
    "            daily_earning_rate = (df[\"Close\"][real_index] - df[buy_column][real_index])/df[buy_column][real_index]\n",
    "            daily_earning_rates = np.append(daily_earning_rates, np.array([daily_earning_rate]))\n",
    "            cumulate_earning_rate = cumulate_earning_rates[-1] + daily_earning_rate\n",
    "            cumulate_earning_rates = np.append(cumulate_earning_rates, np.array([cumulate_earning_rate]))\n",
    "            buy_in = True            \n",
    "        elif (match_point == -1 and buy_in):\n",
    "            last_rate = df[\"Rate\"][real_index-1]/df[\"Rate\"][real_index]\n",
    "            adjust_last_close = df[\"Close\"][real_index-1] * last_rate\n",
    "            daily_earning_rate = (df[sell_column][real_index]-adjust_last_close)/adjust_last_close\n",
    "            daily_earning_rates = np.append(daily_earning_rates, np.array([daily_earning_rate]))\n",
    "            cumulate_earning_rate = cumulate_earning_rates[-1] + daily_earning_rate\n",
    "            cumulate_earning_rates = np.append(cumulate_earning_rates, np.array([cumulate_earning_rate]))\n",
    "            buy_in = False\n",
    "        elif (match_point == 0 and buy_in):   \n",
    "            last_rate = df[\"Rate\"][real_index-1]/df[\"Rate\"][real_index]\n",
    "            adjust_last_close = df[\"Close\"][real_index-1] * last_rate\n",
    "            daily_earning_rate = (df[\"Close\"][real_index]-adjust_last_close)/adjust_last_close\n",
    "            daily_earning_rates = np.append(daily_earning_rates, np.array([daily_earning_rate]))\n",
    "            cumulate_earning_rate = cumulate_earning_rates[-1] + daily_earning_rate\n",
    "            cumulate_earning_rates = np.append(cumulate_earning_rates, np.array([cumulate_earning_rate]))\n",
    "        elif (match_point == 0 and not buy_in and len(cumulate_earning_rates)==0):\n",
    "            daily_earning_rates = np.append(daily_earning_rates, np.array([0]))\n",
    "            cumulate_earning_rates = np.append(cumulate_earning_rates, np.array([0]))\n",
    "        else:\n",
    "            daily_earning_rates = np.append(daily_earning_rates, np.array([0]))\n",
    "            cumulate_earning_rates = np.append(cumulate_earning_rates, np.array([cumulate_earning_rates[-1]]))\n",
    "    df[\"daily_earning_rates\"] = daily_earning_rates\n",
    "    df[\"cumulate_earning_rates\"] = cumulate_earning_rates\n",
    "    return df \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = transform_single_csv()\n",
    "    #df1 = calculate_moving_average(df, 5, price_choice=\"Close\")\n",
    "    df2 = combine_moving_averages(df, 5, 20, price_choice=\"Close\")\n",
    "    df3 = find_average_matches(df2, 5, 20)\n",
    "    df4 = calculate_earnings(df3, 20, buy_column=\"Open\", sell_column=\"Open\")\n",
    "    print(df4[-5:])\n",
    "    df4[\"cumulate_earning_rates\"].plot()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# File System and Daily Combine:\n",
    "\n",
    "import tarfile\n",
    "import numpy as np\n",
    "\n",
    "def write_to_single_csv(date):\n",
    "    if (date <= 20160816):\n",
    "        k_line_file_address = \"/Volumes/Expansion Drive/kline/D\"+str(date)+\".txt\"\n",
    "        factor_file_address = \"/Volumes/Expansion Drive/kline/F\"+str(date)+\".csv\"\n",
    "    else:\n",
    "        k_line_file_address = \"/Volumes/Expansion Drive/dailydata/\"+str(date)+\"/kline/D\"+str(date)+\".txt\"\n",
    "        factor_file_address = \"/Volumes/Expansion Drive/dailydata/\"+str(date)+\"/factor/F\"+str(date)+\".csv\"   \n",
    "    try:\n",
    "        k_line_file = open(k_line_file_address, 'r')\n",
    "        factor_file = open(factor_file_address, 'r')\n",
    "    except:\n",
    "        print(\"Does not Exist\")\n",
    "    for k_line in k_line_file.readlines(): \n",
    "        factor_line = factor_file.readline()\n",
    "        factor = factor_line.split(\",\")[-1]\n",
    "        stock_name = factor_line.split(\",\")[0]\n",
    "        if (k_line[0:8] == factor_line[0:8] and factor_line!=None):\n",
    "            stock_file_name = stock_name.lower()+\"_D_ExDiv.csv\"\n",
    "            stock_file_address = \"/Volumes/Expansion Drive/tkline/\"+stock_file_name        \n",
    "            final_k_line = str(date)+k_line.strip('\\n')[8:]+\",0,\"+factor\n",
    "            try:\n",
    "                stock_file = open(stock_file_address, 'a')\n",
    "                stock_file.write(final_k_line)\n",
    "            except:\n",
    "                continue\n",
    "            stock_file.close()\n",
    "    factor_file.close()\n",
    "    k_line_file.close()\n",
    "    \n",
    "def write_from_kline_to_sh600000_test():\n",
    "    string = \"20160802,15.7900,15.8500,15.6800,15.7500,10877800,0,9.334\\n\"\n",
    "    url = \"/Volumes/Expansion Drive/tkline/sh600000_D_ExDiv.csv\"\n",
    "    file = open(url, 'a')\n",
    "    file.write(string)\n",
    "        \n",
    "def write_from_kline_to_tkline():\n",
    "    dates = np.array([20160804,20160805,20160808,20160809,20160810,20160811,20160812,20160815,20160816])\n",
    "    for date in dates:\n",
    "        write_to_single_csv(date)\n",
    "    return \"Finish Kline to Tkline\"\n",
    "    \n",
    "def write_from_daily_to_tkline():\n",
    "    dates = np.array([\n",
    "        20160817,20160818,20160819,20160822,20160823,20160824,20160825,20160826,20160829,20160830,    \n",
    "        20160831,20160901,20160902,20160905,20160906,20160907,20160908,20160909,20160912,20160913,\n",
    "        20160914,20160919,20160920,20160921,20160922,20160923,20160926,20160927,20160928,20160929,\n",
    "        20160930,20161010,20161011,20161012,20161013,20161014,20161017,20161018,20161019,20161020,\n",
    "        20161021,20161024,20161025,20161026,20161027,20161028,20161031,20161101,20161102,20161103,\n",
    "        20161104,20161107,20161108,20161109,20161110,20161111,20161114,20161115,20161116,20161117,\n",
    "        20161118,20161121,20161122,20161123,20161124,20161125,20161128,20161129,20161130,20161201,\n",
    "        20161202,20161205,20161206,20161207,20161208,20161209,20161212,20161213,20161214,20161215,\n",
    "        20161216,20161219,20161220,20161221,20161222,20161223,20161226,20161227,20161228,20161229,\n",
    "        20161230,20170103,20170104,20170105,20170106,20170109,20170110,20170111,20170112,20170113,\n",
    "        20170116,20170117,20170118,20170119,20170120,20170123,20170124,20170125,20170126,20170203,\n",
    "        20170206,20170207,20170208,20170209,20170210,20170213,20170214,20170215,20170216,20170217]) \n",
    "    counter = 0 \n",
    "    for date in dates:\n",
    "        write_from_single_daily_to_tkline(date)\n",
    "        counter +=1\n",
    "        print(counter)\n",
    "    return \"Finish Daily to Tkline\"\n",
    "\n",
    "def write_from_single_daily_to_tkline(date):\n",
    "    file_address = \"/Volumes/Expansion Drive/dailydata/\"+str(date)+\"_01.tar\"\n",
    "    tar = tarfile.open(file_address)\n",
    "    tar.extractall(\"/Volumes/Expansion Drive/dailydata/\")\n",
    "    tar.close()\n",
    "    write_to_single_csv(date)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Have to run to add single daily file to tkline files everyday.\")\n",
    "    print(\"20160820 is the one to input but have not done yet.\")\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/03/17\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print(datetime.datetime.now().strftime(\"%y/%m/%d\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
